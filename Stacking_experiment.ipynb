{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking experiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvC6EIdtz8vP",
        "outputId": "83261770-ef9f-4c1e-e001-b7e7f84133f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_path = '/content/drive/MyDrive/audd saved files/gujrati dataset'\n",
        "\n",
        "x_mfcc = np.load(files_path+\"/X_mfcc.npy\", allow_pickle=True)\n",
        "x_mel_spectrogram = np.load(files_path+\"/X_mel_spectrogram.npy\", allow_pickle=True)\n",
        "x_zero_crossing_rate = np.load(files_path+\"/X_zero_crossing_rate.npy\", allow_pickle=True)\n",
        "\n",
        "y_mfcc = np.load(files_path+\"/y_mfcc.npy\", allow_pickle=True)\n",
        "y_mel_spectrogram = np.load(files_path+\"/y_mel_spectrogram.npy\", allow_pickle=True)\n",
        "y_zero_crossing_rate = np.load(files_path+\"/y_zero_crossing_rate.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "e7XmuDXI0Kjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# axix = -1 -> along z-axis\n",
        "x_stacked = np.stack((x_mfcc, x_mel_spectrogram,x_zero_crossing_rate), axis = -1)\n"
      ],
      "metadata": {
        "id": "Xc4YCxYo1b59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial featue shape = \",x_mfcc.shape)\n",
        "\n",
        "print(\"x_stacked shape = \",x_stacked.shape)\n",
        "#y_stacked.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p1x7zAA24Oy",
        "outputId": "8ed9622a-8f18-4aaa-805f-e044c610b74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial featue shape =  (1940, 32, 32)\n",
            "x_stacked shape =  (1940, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_stacked, y_mfcc, test_size=0.20, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "x_train =x_train.reshape((x_train.shape[0],32,32,3))\n",
        "x_test =x_test.reshape((x_test.shape[0],32,32,3))\n",
        "\n",
        "print(\"x_train shape = \",x_train.shape)\n",
        "print(\"y_train shape = \",y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy4-xdkX4a7I",
        "outputId": "3d197e12-c417-4792-9e73-7a4e8f4b5806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape =  (1241, 32, 32, 3)\n",
            "y_train shape =  (388,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "def GetCNN():\n",
        "  model = models.Sequential()\n",
        "  \n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))# fully connected\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  \n",
        "  model.add(layers.Dense(10,activation='softmax', use_bias=True))\n",
        "  return model \n",
        "\n",
        "def getModel(modelName=\"ResNet50\", input_shape=(32,32,3)):\n",
        "\n",
        "  input_layr = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "\n",
        "  # Xception, VGG16, VGG19,ResNet101,ResNet152, InceptionV3, InceptionResNetV2,MobileNet,MobileNetV2,DenseNet121,DenseNet169,DenseNet201,EfficientNetB0,EfficientNetB1.. B7\n",
        "  \n",
        "  model=None \n",
        "  if modelName==\"CNN\":\n",
        "    model = GetCNN()\n",
        "    return model\n",
        "  elif modelName==\"Xception\":\n",
        "    model = tf.keras.applications.Xception(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_tensor=input_layr,\n",
        "                                              )\n",
        "  elif modelName==\"ResNet50\":\n",
        "    model = tf.keras.applications.ResNet50(weights=None,\n",
        "                                              include_top = False, \n",
        "                                             )\n",
        "  elif modelName==\"ResNet101\":\n",
        "    model = tf.keras.applications.ResNet101(weights=None,\n",
        "                                              include_top = False\n",
        "                                              )\n",
        "  elif modelName==\"ResNet152\":\n",
        "    model = tf.keras.applications.ResNet152(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"VGG16\":\n",
        "    model = tf.keras.applications.VGG16(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape\n",
        "                                              )\n",
        "\n",
        "  elif modelName==\"VGG19\":\n",
        "    model = tf.keras.applications.VGG19(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"InceptionResNetV2\":\n",
        "    model = tf.keras.applications.InceptionResNetV2(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"MobileNet\":\n",
        "    model = tf.keras.applications.MobileNet(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"MobileNetV2\":\n",
        "    model = tf.keras.applications.MobileNetV2(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"DenseNet121\":\n",
        "    model = tf.keras.applications.DenseNet121(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  elif modelName==\"DenseNet201\":\n",
        "    model = tf.keras.applications.DenseNet201(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)\n",
        "  \n",
        "  elif \"EfficientNet\" in modelName:\n",
        "    dic ={}\n",
        "    models=[tf.keras.applications.EfficientNetB0(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB1(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB2(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB3(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB4(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB5(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB6(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape),\n",
        "            tf.keras.applications.EfficientNetB7(weights=None,\n",
        "                                              include_top = False, \n",
        "                                              input_shape = input_shape)]\n",
        "    for i in range(8):\n",
        "      dic[\"EfficientNetB\"+str(i)] = i \n",
        "    \n",
        "    \n",
        "    model = models[dic[modelName]]\n",
        "\n",
        "\n",
        "  gap = tf.keras.layers.GlobalMaxPooling2D()(model.output)\n",
        "  output = tf.keras.layers.Dense(10, activation='softmax', use_bias=True)(gap)\n",
        "  final_model = tf.keras.Model(model.input, output)\n",
        "  return final_model\n",
        "# x_train = 100 , 32 x 32  \n",
        "# 32 x 32 x 1  \n",
        "x_test = x_test.reshape((x_test.shape[0],32,32,3))\n",
        "x_train = x_train.reshape((x_train.shape[0],32,32,3))\n",
        "x_val = x_val.reshape((x_val.shape[0],32,32,3))"
      ],
      "metadata": {
        "id": "WQ6Bq7KY4x2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "label_as_binary = LabelBinarizer()\n",
        "train__y_labels = label_as_binary.fit_transform(y_train)\n",
        "\n",
        "y_val = label_as_binary.fit_transform(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f-Nv8ESC_0s",
        "outputId": "afdb9d47-1406-496a-bdb7-c3dda38bd265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(311, 32, 32, 3)\n",
            "(311,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_path = '/content/drive/MyDrive/audd saved files/gujrati dataset/models'\n",
        "\n",
        "\n",
        "feature = \"stacked_model\"\n",
        "acc={}\n",
        "batch_size=256\n",
        "epochs=150\n",
        "Models= [\"MobileNetV2\"] #\"EfficientNetB0\",\"EfficientNetB1\"] \n",
        "        #  \"DenseNet121\",\"DenseNet169\",\"DenseNet201\"] #,\n",
        "        #  \n",
        "        #  \"VGG16\", \"VGG19\",\"ResNet101\",\"ResNet152\", \n",
        "        #  \"DenseNet121\",\"DenseNet169\",\"DenseNet201\", ] \n",
        "# Done = [\"MobileNet\",\"MobileNetV2\",Xception, \"EfficientNetB0\",\"EfficientNetB1\" , \n",
        "# \"EfficientNetB2\",\"EfficientNetB3\",\"EfficientNetB4\",\"EfficientNetB5\", ,\"EfficientNetB6\",\"EfficientNetB7\" ]\n",
        "# Done = []\n",
        "for modelName in Models:\n",
        "  acc[modelName]=[] \n",
        "  print(\"Training \", modelName)\n",
        "  final_model = getModel(modelName=modelName)\n",
        "  final_model.compile(loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = [\"accuracy\"],\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "  callbacks = ModelCheckpoint(model_path+\"/\"+modelName+\"_{}_.h5\".format(feature), monitor='val_accuracy',\n",
        "                                    mode='max',\n",
        "                                    save_best_only=True,\n",
        "                                    verbose=1)\n",
        "  final_model.summary()\n",
        "  history = final_model.fit(x_train, train__y_labels, batch_size=batch_size, validation_data=(x_val, y_val), epochs=epochs, verbose = 1  ,callbacks=[callbacks])\n",
        "  np.save(model_path+\"/{}_{}_history.npy\".format(feature, modelName),history)\n",
        "  hist_df = pd.DataFrame(history.history) \n",
        "  hist_df.to_csv(model_path+\"/\"+modelName+\"_{}_CSV_.csv\".format(feature))\n",
        "  acc[modelName].append(final_model.evaluate(x_test,y_test)[1])\n",
        "df =pd.DataFrame(acc)\n",
        "df.to_csv(model_path+\"/\"+Models[0]+\"{}.csv\".format(feature))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i4KqCCHT-dUB",
        "outputId": "ddf84031-c468-4546-e7c7-76428a1f68e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training  MobileNetV2\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 16, 16, 32)   864         ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 16, 16, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 16, 16, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 16, 16, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 16, 16, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 16, 16, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 16, 16, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 16, 16, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 16, 16, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 17, 17, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 8, 8, 24)     2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 8, 8, 144)   1296        ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 8, 8, 144)   576         ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 8, 8, 144)    0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 8, 8, 24)     3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 8, 8, 24)     0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 9, 9, 144)    0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 4, 4, 144)   1296        ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 4, 4, 144)   576         ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 4, 4, 144)    0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 4, 4, 32)     4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 4, 4, 32)     0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 4, 4, 32)     0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 5, 5, 192)    0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 2, 2, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 2, 2, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 2, 2, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 2, 2, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 2, 2, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 2, 2, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 2, 2, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 2, 2, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 2, 2, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 2, 2, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 2, 2, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 2, 2, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 2, 2, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 2, 2, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 2, 2, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 3, 3, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 1, 1, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 1, 1, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 1, 1, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 1, 1, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 1, 1, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 1, 1, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 1, 1, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 1, 1, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 1, 1, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling2d_7 (Global  (None, 1280)        0           ['out_relu[0][0]']               \n",
            " MaxPooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 10)           12810       ['global_max_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 2,236,682\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.5676 - accuracy: 0.1144\n",
            "Epoch 1: val_accuracy improved from -inf to 0.08039, saving model to /content/drive/MyDrive/audd saved files/gujrati dataset/models/MobileNetV2_stacked_model_.h5\n",
            "5/5 [==============================] - 9s 677ms/step - loss: 4.5676 - accuracy: 0.1144 - val_loss: 2.3222 - val_accuracy: 0.0804\n",
            "Epoch 2/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.6823 - accuracy: 0.1789\n",
            "Epoch 2: val_accuracy improved from 0.08039 to 0.09968, saving model to /content/drive/MyDrive/audd saved files/gujrati dataset/models/MobileNetV2_stacked_model_.h5\n",
            "5/5 [==============================] - 1s 344ms/step - loss: 2.6823 - accuracy: 0.1789 - val_loss: 2.7470 - val_accuracy: 0.0997\n",
            "Epoch 3/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1231 - accuracy: 0.2659\n",
            "Epoch 3: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 2.1231 - accuracy: 0.2659 - val_loss: 3.2478 - val_accuracy: 0.0804\n",
            "Epoch 4/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2969 - accuracy: 0.2611\n",
            "Epoch 4: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 2.2969 - accuracy: 0.2611 - val_loss: 2.8229 - val_accuracy: 0.0997\n",
            "Epoch 5/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1248 - accuracy: 0.2442\n",
            "Epoch 5: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 2.1248 - accuracy: 0.2442 - val_loss: 2.4179 - val_accuracy: 0.0997\n",
            "Epoch 6/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.7789 - accuracy: 0.3086\n",
            "Epoch 6: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 1.7789 - accuracy: 0.3086 - val_loss: 2.4479 - val_accuracy: 0.0804\n",
            "Epoch 7/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4983 - accuracy: 0.3844\n",
            "Epoch 7: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 1.4983 - accuracy: 0.3844 - val_loss: 2.4488 - val_accuracy: 0.0804\n",
            "Epoch 8/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2734 - accuracy: 0.4529\n",
            "Epoch 8: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 1.2734 - accuracy: 0.4529 - val_loss: 2.3870 - val_accuracy: 0.0804\n",
            "Epoch 9/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0967 - accuracy: 0.4964\n",
            "Epoch 9: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 1.0967 - accuracy: 0.4964 - val_loss: 2.3564 - val_accuracy: 0.0932\n",
            "Epoch 10/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9299 - accuracy: 0.5512\n",
            "Epoch 10: val_accuracy did not improve from 0.09968\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.9299 - accuracy: 0.5512 - val_loss: 2.3884 - val_accuracy: 0.0932\n",
            "Epoch 11/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7630 - accuracy: 0.6624\n",
            "Epoch 11: val_accuracy improved from 0.09968 to 0.10611, saving model to /content/drive/MyDrive/audd saved files/gujrati dataset/models/MobileNetV2_stacked_model_.h5\n",
            "5/5 [==============================] - 1s 341ms/step - loss: 0.7630 - accuracy: 0.6624 - val_loss: 2.4021 - val_accuracy: 0.1061\n",
            "Epoch 12/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7204\n",
            "Epoch 12: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.6330 - accuracy: 0.7204 - val_loss: 2.4960 - val_accuracy: 0.1061\n",
            "Epoch 13/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.7341\n",
            "Epoch 13: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6363 - accuracy: 0.7341 - val_loss: 2.6080 - val_accuracy: 0.1061\n",
            "Epoch 14/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.7865\n",
            "Epoch 14: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.5404 - accuracy: 0.7865 - val_loss: 2.8243 - val_accuracy: 0.1061\n",
            "Epoch 15/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8590\n",
            "Epoch 15: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.4111 - accuracy: 0.8590 - val_loss: 3.0505 - val_accuracy: 0.1061\n",
            "Epoch 16/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8421\n",
            "Epoch 16: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.3901 - accuracy: 0.8421 - val_loss: 3.0547 - val_accuracy: 0.1061\n",
            "Epoch 17/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8759\n",
            "Epoch 17: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.3255 - accuracy: 0.8759 - val_loss: 3.3212 - val_accuracy: 0.1061\n",
            "Epoch 18/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9025\n",
            "Epoch 18: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2887 - accuracy: 0.9025 - val_loss: 3.3896 - val_accuracy: 0.1061\n",
            "Epoch 19/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8824\n",
            "Epoch 19: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.3597 - accuracy: 0.8824 - val_loss: 3.3405 - val_accuracy: 0.1061\n",
            "Epoch 20/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.8969\n",
            "Epoch 20: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2891 - accuracy: 0.8969 - val_loss: 3.1482 - val_accuracy: 0.1061\n",
            "Epoch 21/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9267\n",
            "Epoch 21: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.2330 - accuracy: 0.9267 - val_loss: 3.1139 - val_accuracy: 0.1061\n",
            "Epoch 22/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9476\n",
            "Epoch 22: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2107 - accuracy: 0.9476 - val_loss: 3.0699 - val_accuracy: 0.1061\n",
            "Epoch 23/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9347\n",
            "Epoch 23: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.1776 - accuracy: 0.9347 - val_loss: 3.2359 - val_accuracy: 0.1061\n",
            "Epoch 24/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9380\n",
            "Epoch 24: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2007 - accuracy: 0.9380 - val_loss: 3.2103 - val_accuracy: 0.1061\n",
            "Epoch 25/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9363\n",
            "Epoch 25: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.1863 - accuracy: 0.9363 - val_loss: 3.1202 - val_accuracy: 0.1061\n",
            "Epoch 26/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.9299\n",
            "Epoch 26: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2624 - accuracy: 0.9299 - val_loss: 2.8853 - val_accuracy: 0.1061\n",
            "Epoch 27/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9444\n",
            "Epoch 27: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.1619 - accuracy: 0.9444 - val_loss: 3.0685 - val_accuracy: 0.1061\n",
            "Epoch 28/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9452\n",
            "Epoch 28: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.1573 - accuracy: 0.9452 - val_loss: 2.9753 - val_accuracy: 0.1061\n",
            "Epoch 29/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9500\n",
            "Epoch 29: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.1582 - accuracy: 0.9500 - val_loss: 2.8499 - val_accuracy: 0.1061\n",
            "Epoch 30/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9750\n",
            "Epoch 30: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0944 - accuracy: 0.9750 - val_loss: 2.7568 - val_accuracy: 0.0932\n",
            "Epoch 31/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9718\n",
            "Epoch 31: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.1030 - accuracy: 0.9718 - val_loss: 2.7050 - val_accuracy: 0.1061\n",
            "Epoch 32/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9613\n",
            "Epoch 32: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.1256 - accuracy: 0.9613 - val_loss: 2.6978 - val_accuracy: 0.0932\n",
            "Epoch 33/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9774\n",
            "Epoch 33: val_accuracy did not improve from 0.10611\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.0760 - accuracy: 0.9774 - val_loss: 2.7453 - val_accuracy: 0.0932\n",
            "Epoch 34/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9807\n",
            "Epoch 34: val_accuracy improved from 0.10611 to 0.12540, saving model to /content/drive/MyDrive/audd saved files/gujrati dataset/models/MobileNetV2_stacked_model_.h5\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.0784 - accuracy: 0.9807 - val_loss: 2.7286 - val_accuracy: 0.1254\n",
            "Epoch 35/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9774\n",
            "Epoch 35: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0790 - accuracy: 0.9774 - val_loss: 2.7332 - val_accuracy: 0.1254\n",
            "Epoch 36/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9815\n",
            "Epoch 36: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 2.8128 - val_accuracy: 0.1254\n",
            "Epoch 37/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9815\n",
            "Epoch 37: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 2.7698 - val_accuracy: 0.1254\n",
            "Epoch 38/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9774\n",
            "Epoch 38: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 2.8062 - val_accuracy: 0.1254\n",
            "Epoch 39/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9863\n",
            "Epoch 39: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 2.8095 - val_accuracy: 0.1254\n",
            "Epoch 40/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9839\n",
            "Epoch 40: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 2.8268 - val_accuracy: 0.1254\n",
            "Epoch 41/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9815\n",
            "Epoch 41: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0727 - accuracy: 0.9815 - val_loss: 2.7332 - val_accuracy: 0.1254\n",
            "Epoch 42/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9750\n",
            "Epoch 42: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 2.7638 - val_accuracy: 0.1254\n",
            "Epoch 43/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9807\n",
            "Epoch 43: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.0666 - accuracy: 0.9807 - val_loss: 2.7999 - val_accuracy: 0.0997\n",
            "Epoch 44/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9750\n",
            "Epoch 44: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0886 - accuracy: 0.9750 - val_loss: 2.7242 - val_accuracy: 0.0997\n",
            "Epoch 45/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9758\n",
            "Epoch 45: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0803 - accuracy: 0.9758 - val_loss: 2.8311 - val_accuracy: 0.0997\n",
            "Epoch 46/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9782\n",
            "Epoch 46: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0664 - accuracy: 0.9782 - val_loss: 3.0055 - val_accuracy: 0.0997\n",
            "Epoch 47/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9823\n",
            "Epoch 47: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 3.0444 - val_accuracy: 0.0997\n",
            "Epoch 48/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9718\n",
            "Epoch 48: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0922 - accuracy: 0.9718 - val_loss: 3.1358 - val_accuracy: 0.0997\n",
            "Epoch 49/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9799\n",
            "Epoch 49: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0744 - accuracy: 0.9799 - val_loss: 3.0989 - val_accuracy: 0.0997\n",
            "Epoch 50/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9710\n",
            "Epoch 50: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0830 - accuracy: 0.9710 - val_loss: 3.1313 - val_accuracy: 0.0997\n",
            "Epoch 51/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9815\n",
            "Epoch 51: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0708 - accuracy: 0.9815 - val_loss: 3.0426 - val_accuracy: 0.0997\n",
            "Epoch 52/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9782\n",
            "Epoch 52: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0920 - accuracy: 0.9782 - val_loss: 2.9545 - val_accuracy: 0.0997\n",
            "Epoch 53/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9839\n",
            "Epoch 53: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 2.9383 - val_accuracy: 0.0997\n",
            "Epoch 54/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9879\n",
            "Epoch 54: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 2.9030 - val_accuracy: 0.0997\n",
            "Epoch 55/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9927\n",
            "Epoch 55: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 3.0061 - val_accuracy: 0.0997\n",
            "Epoch 56/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9944\n",
            "Epoch 56: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 3.0064 - val_accuracy: 0.0997\n",
            "Epoch 57/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9936\n",
            "Epoch 57: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0321 - accuracy: 0.9936 - val_loss: 3.0043 - val_accuracy: 0.0997\n",
            "Epoch 58/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9952\n",
            "Epoch 58: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 3.0498 - val_accuracy: 0.0997\n",
            "Epoch 59/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9911\n",
            "Epoch 59: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 3.0448 - val_accuracy: 0.0997\n",
            "Epoch 60/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9903\n",
            "Epoch 60: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 1s 117ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 3.0770 - val_accuracy: 0.0997\n",
            "Epoch 61/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9871\n",
            "Epoch 61: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0604 - accuracy: 0.9871 - val_loss: 3.1882 - val_accuracy: 0.0997\n",
            "Epoch 62/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9847\n",
            "Epoch 62: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0612 - accuracy: 0.9847 - val_loss: 3.2635 - val_accuracy: 0.0997\n",
            "Epoch 63/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9831\n",
            "Epoch 63: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0651 - accuracy: 0.9831 - val_loss: 3.2271 - val_accuracy: 0.0997\n",
            "Epoch 64/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9718\n",
            "Epoch 64: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0943 - accuracy: 0.9718 - val_loss: 3.4248 - val_accuracy: 0.0997\n",
            "Epoch 65/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9629\n",
            "Epoch 65: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.1178 - accuracy: 0.9629 - val_loss: 3.5528 - val_accuracy: 0.0997\n",
            "Epoch 66/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9871\n",
            "Epoch 66: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0450 - accuracy: 0.9871 - val_loss: 3.4218 - val_accuracy: 0.0997\n",
            "Epoch 67/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9758\n",
            "Epoch 67: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0944 - accuracy: 0.9758 - val_loss: 3.3883 - val_accuracy: 0.0997\n",
            "Epoch 68/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9823\n",
            "Epoch 68: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0625 - accuracy: 0.9823 - val_loss: 3.3940 - val_accuracy: 0.0997\n",
            "Epoch 69/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9815\n",
            "Epoch 69: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0724 - accuracy: 0.9815 - val_loss: 3.4398 - val_accuracy: 0.0997\n",
            "Epoch 70/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9895\n",
            "Epoch 70: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 3.4431 - val_accuracy: 0.0997\n",
            "Epoch 71/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9863\n",
            "Epoch 71: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0591 - accuracy: 0.9863 - val_loss: 3.3980 - val_accuracy: 0.0997\n",
            "Epoch 72/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9919\n",
            "Epoch 72: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 3.2636 - val_accuracy: 0.0997\n",
            "Epoch 73/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9927\n",
            "Epoch 73: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 3.1868 - val_accuracy: 0.0997\n",
            "Epoch 74/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9968\n",
            "Epoch 74: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 3.2549 - val_accuracy: 0.0997\n",
            "Epoch 75/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9927\n",
            "Epoch 75: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 3.2531 - val_accuracy: 0.0997\n",
            "Epoch 76/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9927\n",
            "Epoch 76: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 3.1879 - val_accuracy: 0.0997\n",
            "Epoch 77/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9879\n",
            "Epoch 77: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.0578 - accuracy: 0.9879 - val_loss: 3.4401 - val_accuracy: 0.0997\n",
            "Epoch 78/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9952\n",
            "Epoch 78: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 3.5866 - val_accuracy: 0.0997\n",
            "Epoch 79/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9952\n",
            "Epoch 79: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 3.5400 - val_accuracy: 0.0997\n",
            "Epoch 80/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9952\n",
            "Epoch 80: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0239 - accuracy: 0.9952 - val_loss: 3.4965 - val_accuracy: 0.0997\n",
            "Epoch 81/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9919\n",
            "Epoch 81: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 3.5327 - val_accuracy: 0.0997\n",
            "Epoch 82/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9887\n",
            "Epoch 82: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0489 - accuracy: 0.9887 - val_loss: 3.5874 - val_accuracy: 0.0997\n",
            "Epoch 83/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9879\n",
            "Epoch 83: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 3.5523 - val_accuracy: 0.0997\n",
            "Epoch 84/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9807\n",
            "Epoch 84: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0713 - accuracy: 0.9807 - val_loss: 3.5670 - val_accuracy: 0.0997\n",
            "Epoch 85/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9879\n",
            "Epoch 85: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 3.6993 - val_accuracy: 0.0997\n",
            "Epoch 86/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9831\n",
            "Epoch 86: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 3.6807 - val_accuracy: 0.0997\n",
            "Epoch 87/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9758\n",
            "Epoch 87: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0892 - accuracy: 0.9758 - val_loss: 3.5663 - val_accuracy: 0.0997\n",
            "Epoch 88/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9758\n",
            "Epoch 88: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.1229 - accuracy: 0.9758 - val_loss: 3.5366 - val_accuracy: 0.0997\n",
            "Epoch 89/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9831\n",
            "Epoch 89: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 3.5358 - val_accuracy: 0.0997\n",
            "Epoch 90/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9879\n",
            "Epoch 90: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 3.3807 - val_accuracy: 0.0997\n",
            "Epoch 91/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9911\n",
            "Epoch 91: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0341 - accuracy: 0.9911 - val_loss: 3.2460 - val_accuracy: 0.0997\n",
            "Epoch 92/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9887\n",
            "Epoch 92: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.2295 - val_accuracy: 0.0997\n",
            "Epoch 93/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9936\n",
            "Epoch 93: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0345 - accuracy: 0.9936 - val_loss: 3.3278 - val_accuracy: 0.0997\n",
            "Epoch 94/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9927\n",
            "Epoch 94: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 3.2354 - val_accuracy: 0.0997\n",
            "Epoch 95/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9879\n",
            "Epoch 95: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 3.3039 - val_accuracy: 0.0997\n",
            "Epoch 96/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9919\n",
            "Epoch 96: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 3.3134 - val_accuracy: 0.0997\n",
            "Epoch 97/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9927\n",
            "Epoch 97: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 3.2696 - val_accuracy: 0.0997\n",
            "Epoch 98/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9927\n",
            "Epoch 98: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 3.1990 - val_accuracy: 0.0997\n",
            "Epoch 99/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919\n",
            "Epoch 99: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 3.1886 - val_accuracy: 0.0997\n",
            "Epoch 100/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968\n",
            "Epoch 100: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 3.2798 - val_accuracy: 0.0997\n",
            "Epoch 101/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9960\n",
            "Epoch 101: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 3.3712 - val_accuracy: 0.0997\n",
            "Epoch 102/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968\n",
            "Epoch 102: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 3.4011 - val_accuracy: 0.0997\n",
            "Epoch 103/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9976\n",
            "Epoch 103: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 3.4309 - val_accuracy: 0.0997\n",
            "Epoch 104/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9984\n",
            "Epoch 104: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 3.4088 - val_accuracy: 0.0997\n",
            "Epoch 105/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9976\n",
            "Epoch 105: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 3.3975 - val_accuracy: 0.0997\n",
            "Epoch 106/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9919\n",
            "Epoch 106: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0296 - accuracy: 0.9919 - val_loss: 3.3126 - val_accuracy: 0.0997\n",
            "Epoch 107/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9871\n",
            "Epoch 107: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0468 - accuracy: 0.9871 - val_loss: 3.4138 - val_accuracy: 0.0997\n",
            "Epoch 108/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9863\n",
            "Epoch 108: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 3.4267 - val_accuracy: 0.0997\n",
            "Epoch 109/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9936\n",
            "Epoch 109: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0166 - accuracy: 0.9936 - val_loss: 3.3913 - val_accuracy: 0.0997\n",
            "Epoch 110/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9936\n",
            "Epoch 110: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 3.4060 - val_accuracy: 0.0997\n",
            "Epoch 111/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9871\n",
            "Epoch 111: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0859 - accuracy: 0.9871 - val_loss: 3.6638 - val_accuracy: 0.0997\n",
            "Epoch 112/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9863\n",
            "Epoch 112: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0665 - accuracy: 0.9863 - val_loss: 3.5082 - val_accuracy: 0.0997\n",
            "Epoch 113/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9823\n",
            "Epoch 113: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0643 - accuracy: 0.9823 - val_loss: 3.4998 - val_accuracy: 0.0997\n",
            "Epoch 114/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9774\n",
            "Epoch 114: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 3.1206 - val_accuracy: 0.0997\n",
            "Epoch 115/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9895\n",
            "Epoch 115: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 3.1685 - val_accuracy: 0.0997\n",
            "Epoch 116/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9879\n",
            "Epoch 116: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 3.0807 - val_accuracy: 0.0997\n",
            "Epoch 117/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 117: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 3.0134 - val_accuracy: 0.0997\n",
            "Epoch 118/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9976\n",
            "Epoch 118: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 3.0200 - val_accuracy: 0.0997\n",
            "Epoch 119/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 119: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0785 - val_accuracy: 0.0997\n",
            "Epoch 120/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9984\n",
            "Epoch 120: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 3.1302 - val_accuracy: 0.0997\n",
            "Epoch 121/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9992\n",
            "Epoch 121: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 3.1730 - val_accuracy: 0.0997\n",
            "Epoch 122/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
            "Epoch 122: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2354 - val_accuracy: 0.0997\n",
            "Epoch 123/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 123: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 3.2454 - val_accuracy: 0.0997\n",
            "Epoch 124/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.0812e-04 - accuracy: 1.0000\n",
            "Epoch 124: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 5.0812e-04 - accuracy: 1.0000 - val_loss: 3.2307 - val_accuracy: 0.0997\n",
            "Epoch 125/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9976\n",
            "Epoch 125: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 3.2308 - val_accuracy: 0.0997\n",
            "Epoch 126/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9984\n",
            "Epoch 126: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 3.2347 - val_accuracy: 0.0997\n",
            "Epoch 127/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9976\n",
            "Epoch 127: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 3.2707 - val_accuracy: 0.0997\n",
            "Epoch 128/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9919\n",
            "Epoch 128: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 3.2723 - val_accuracy: 0.0997\n",
            "Epoch 129/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9919\n",
            "Epoch 129: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0442 - accuracy: 0.9919 - val_loss: 3.2358 - val_accuracy: 0.0997\n",
            "Epoch 130/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9952\n",
            "Epoch 130: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0218 - accuracy: 0.9952 - val_loss: 3.1683 - val_accuracy: 0.0997\n",
            "Epoch 131/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9911\n",
            "Epoch 131: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0334 - accuracy: 0.9911 - val_loss: 3.0993 - val_accuracy: 0.0997\n",
            "Epoch 132/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9968\n",
            "Epoch 132: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 2.9597 - val_accuracy: 0.0997\n",
            "Epoch 133/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
            "Epoch 133: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 3.0115 - val_accuracy: 0.0997\n",
            "Epoch 134/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9960\n",
            "Epoch 134: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 2.9963 - val_accuracy: 0.0997\n",
            "Epoch 135/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9944\n",
            "Epoch 135: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 2.9351 - val_accuracy: 0.0997\n",
            "Epoch 136/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9952\n",
            "Epoch 136: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0233 - accuracy: 0.9952 - val_loss: 2.9961 - val_accuracy: 0.0997\n",
            "Epoch 137/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9968\n",
            "Epoch 137: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 2.9657 - val_accuracy: 0.0997\n",
            "Epoch 138/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9976\n",
            "Epoch 138: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 3.1836 - val_accuracy: 0.0997\n",
            "Epoch 139/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9976\n",
            "Epoch 139: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 3.3529 - val_accuracy: 0.0997\n",
            "Epoch 140/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
            "Epoch 140: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 3.4086 - val_accuracy: 0.0997\n",
            "Epoch 141/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9960\n",
            "Epoch 141: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 3.3931 - val_accuracy: 0.0997\n",
            "Epoch 142/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9952\n",
            "Epoch 142: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 3.4039 - val_accuracy: 0.0997\n",
            "Epoch 143/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9903\n",
            "Epoch 143: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0607 - accuracy: 0.9903 - val_loss: 3.4717 - val_accuracy: 0.0997\n",
            "Epoch 144/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9823\n",
            "Epoch 144: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0674 - accuracy: 0.9823 - val_loss: 3.5261 - val_accuracy: 0.0997\n",
            "Epoch 145/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9879\n",
            "Epoch 145: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 3.3435 - val_accuracy: 0.0997\n",
            "Epoch 146/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9911\n",
            "Epoch 146: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 3.1515 - val_accuracy: 0.0997\n",
            "Epoch 147/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9944\n",
            "Epoch 147: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0334 - accuracy: 0.9944 - val_loss: 3.2572 - val_accuracy: 0.0997\n",
            "Epoch 148/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9976\n",
            "Epoch 148: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 3.4898 - val_accuracy: 0.0997\n",
            "Epoch 149/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9968\n",
            "Epoch 149: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 3.5776 - val_accuracy: 0.0997\n",
            "Epoch 150/150\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9944\n",
            "Epoch 150: val_accuracy did not improve from 0.12540\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 3.6657 - val_accuracy: 0.0997\n",
            "INFO:tensorflow:Assets written to: ram://365c79ca-eea2-4c19-b9cd-6578a6c78128/assets\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-92997cabf2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mhist_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mhist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_{}_CSV_.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"{}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get csv files\n",
        "import pandas as pd\n",
        "models = [\"EfficientNetB0_mel_spectrogram_CSV_.csv\", \"EfficientNetB0_mfcc_CSV_.csv\", \"EfficientNetB0_zero_crossing_rate_CSV_.csv\",\n",
        "          \"mel_spectrogram_history.npy\",\"mel_spectrogram_MobileNet_history.npy\", \"MobileNet_mel_spectrogram_CSV_.csv\", \"MobileNet_mfcc_CSV_.csv\",\n",
        "          \"MobileNet_zero_crossing_rate_CSV_.csv\", \"\"]\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/audd saved files/models/mfcc_EfficientNetB0_history.npy\"\n",
        "\n",
        "\n",
        "history = np.load(path, allow_pickle=True)\n",
        "\n",
        "\n",
        "\"\"\"import matplotlib.pylab as plt\n",
        "from matplotlib.pyplot import figure\n",
        "figure(figsize=(8, 6))\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VaWgSw9q8sDx",
        "outputId": "1e3b98c8-f7f1-4667-b694-e65ae89d8677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import matplotlib.pylab as plt\\nfrom matplotlib.pyplot import figure\\nfigure(figsize=(8, 6))\\nplt.plot(history['loss'])\\nplt.plot(history['val_loss'])\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='upper left')\\nplt.show()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmZLra8FMlC",
        "outputId": "39579f35-c797-4ef1-a910-4f4f6b22f56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7f8de2fe9f10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "models = [\"CNN\",  \"EfficientNetB0\",\"EfficientNetB1\" , \"EfficientNetB2\",\n",
        "          \"EfficientNetB3\",\"EfficientNetB4\",\"EfficientNetB5\", \"EfficientNetB6\",\"EfficientNetB7\" ]\n",
        "dc={}\n",
        "plt.figure(figsize=(25,15))\n",
        "for model in models:\n",
        "  dc[model] = []\n",
        "for model in models:\n",
        "    pth = \"/content/drive/MyDrive/\"+model+\"_0_.csv\"\n",
        "    df=pd.read_csv(pth)\n",
        "    plt.plot(range(len(df)),df[\"val_accuracy\"],label=model,linewidth=3.5);\n",
        "plt.rc('legend', fontsize=25)\n",
        "plt.title(\"Validation Accuracy Vs Epochs\", fontsize=40,fontweight=\"bold\")\n",
        "plt.xlabel('Epochs',fontsize=30, fontweight=\"bold\")\n",
        "plt.ylabel('Accuracy', fontsize=30,fontweight=\"bold\")\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "plt.legend()\n",
        "plt.savefig(\"accuracy.png\",transparent=True ,dpi=250)"
      ],
      "metadata": {
        "id": "ZwQlBMgV8u_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}