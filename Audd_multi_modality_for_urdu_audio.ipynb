{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audd multi-modality for urdu audio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/turab45/Audd-multi-modality-for-urdu-audio/blob/master/Audd_multi_modality_for_urdu_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcHdBfeFdC47",
        "outputId": "f37ef48c-461d-46d2-ee43-dd7b9cd7bb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tZ1TxfO9Y56",
        "outputId": "141ebc24-64a4-4a92-8ae9-2fbcf78027e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/dataset_old.zip'\n",
        "#!git clone https://github.com/Nikunj1729/free-spoken-gujarati-digit-dataset"
      ],
      "metadata": {
        "id": "T7tEtjoDeDkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESSING\n",
        "# Feature extraction methods\n",
        "\n",
        "def CalculateZeroCrossingRate(file_location):\n",
        "    y, sr = librosa.load(file_location)\n",
        "    zCross = librosa.feature.zero_crossing_rate(y=y)\n",
        "    dim = (32, 32)\n",
        "    resized = cv2.resize(zCross, dim, interpolation = cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "def CalculateMelSpectrogram(file_location):\n",
        "    y, sr = librosa.load(file_location)\n",
        "    melSpec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    melSpec_dB = librosa.power_to_db(melSpec)\n",
        "    dim = (32, 32)\n",
        "    resized = cv2.resize(melSpec_dB, dim, interpolation = cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "\n",
        "def CalculateMFCC(file_location):\n",
        "    y, sr = librosa.load(file_location)\n",
        "    melSpec = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    dim = (32, 32)\n",
        "    resized = cv2.resize(melSpec, dim, interpolation = cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n"
      ],
      "metadata": {
        "id": "wSSuTUoKdZYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gQiVbsAfsgj",
        "outputId": "2ba1edf1-4383-4ca0-e0c1-eabf134352d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for i in range(10):\n",
        "  j = '/content/dataset'\n",
        "  print(os.listdir(j))\n",
        "  for k in os.listdir(j):\n",
        "    print(k)\n",
        "    if \".DS_\" in k:\n",
        "      continue\n",
        "\n",
        "    for t in os.listdir(j+\"/\"+k):\n",
        "      #print(\"path = \", os.listdir(j+\"/\"+k))\n",
        "      if \".DS_\" in k:\n",
        "        continue \n",
        "      print(t.split(\"WA\")[1].split(\".\")[0])\n",
        "      #print(t.split(\"D\")[1][0])\n",
        "      break\n",
        "    break \n",
        "  break '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BZCldknfBtv",
        "outputId": "4c4f757b-7416-47de-df04-81bd971adb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['7', '8', '1', '6', '3', '2', '5', '4', '0', '9']\n",
            "7\n",
            "6614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESSING\n",
        "\n",
        "files_path = '/content/drive/MyDrive/audd saved files'\n",
        "if not os.path.exists(\"processed_data\"):\n",
        "  os.mkdir(\"processed_data\")\n",
        "x=[]\n",
        "y=[]\n",
        "Total=23500\n",
        "count=0\n",
        "\n",
        "j = '/content/dataset'\n",
        "print(os.listdir(j))\n",
        "for k in os.listdir(j):\n",
        "  print(k)\n",
        "  if \".DS_\" in k:\n",
        "    continue\n",
        "\n",
        "  for t in os.listdir(j+\"/\"+k):\n",
        "    #print(\"path = \", os.listdir(j+\"/\"+k))\n",
        "    if \".DS_\" in k:\n",
        "      continue\n",
        "    print(count,t)\n",
        "    x.append(CalculateZeroCrossingRate((j+\"/\"+k+\"/\"+t))) #CalculateZeroCrossingRate(), CalculateMelSpectrogram(), CalculateMFCC() \n",
        "    y.append(int(k))   \n",
        "    count+=1\n",
        "  if count%300==0:\n",
        "    print(Total-count)\n",
        "  \n",
        "x=np.array(x)\n",
        "y=np.array(y)\n",
        "np.save(files_path+\"/X_zero_crossing_rate\",x) # _melspectrogram, zero_crossing_rate, mfcc\n",
        "np.save(files_path+\"/y_zero_crossing_rate\",y) "
      ],
      "metadata": {
        "id": "GznIG9AtyP-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load files \n",
        "files_path = '/content/drive/MyDrive/audd saved files'\n",
        "\n",
        "x_melspectrogram = np.load(files_path+\"/X_mfcc.npy\", allow_pickle=True)\n",
        "y_melspectrogram = np.load(files_path+\"/y_mfcc.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "MQi3OLjocbH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = x_melspectrogram\n",
        "y = y_melspectrogram\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "np.save(files_path+\"/x_mfcc_train\",x_train)\n",
        "np.save(files_path+\"/y_mfcc_train\",y_train)\n",
        "np.save(files_path+\"/x_mfcc_test\",x_test)\n",
        "np.save(files_path+\"/y_mfcc_test\",y_test)"
      ],
      "metadata": {
        "id": "mggTLnkMbQ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "x_train = np.load(files_path+\"/x_mfcc_train.npy\", allow_pickle=True)\n",
        "x_test = np.load(files_path+\"/x_mfcc_test.npy\",allow_pickle=True) \n",
        "y_train = np.load(files_path+\"/x_mfcc_train.npy\", allow_pickle=True)\n",
        "y_test = np.load(files_path+\"/y_mfcc_test.npy\",allow_pickle=True)"
      ],
      "metadata": {
        "id": "YB5XpKbReAXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_melspectrogram))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elOv-AAYmZo_",
        "outputId": "f476a9b5-6890-4f9f-f6ee-7c59f4002200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train =x_train.reshape((x_train.shape[0],32,32,1))\n",
        "x_test =x_test.reshape((x_test.shape[0],32,32,1))"
      ],
      "metadata": {
        "id": "HNPZQvHEeZVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "2o-1LnghejML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "def GetCNN():\n",
        "  model = models.Sequential()\n",
        "  \n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))# fully connected\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  \n",
        "  model.add(layers.Dense(10,activation='softmax', use_bias=True))\n",
        "  return model "
      ],
      "metadata": {
        "id": "XjCh_6b8efjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "label_as_binary = LabelBinarizer()\n",
        "train_y = label_as_binary.fit_transform(y_train)\n",
        "test_y = label_as_binary.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "6JgRD45QervB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/audd saved files/models'\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "cnn_model = GetCNN()\n",
        "print(cnn_model.summary())\n",
        "cnn_model.compile(loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = [\"accuracy\"],\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "callbacks = ModelCheckpoint(save_path+\"/melspectrogram_model_.h5\", monitor='val_accuracy',\n",
        "                                    mode='max',\n",
        "                                    save_best_only=True,\n",
        "                                    verbose=1)\n",
        "\n",
        "print(\"X train shape = \",x_train.shape)\n",
        "print(\"y train shape = \",train_y.shape)\n",
        "\n",
        "cnn_model.fit(x_train, train_y, batch_size=64, epochs=150, verbose=1, validation_split=0.1, callbacks=[callbacks])\n",
        "#import keras\n",
        "#cnn_model = keras.models.load_model(save_path+\"/melspectrogram_model_.h5\")\n",
        "#print(\"Test Accuracy is \", cnn_model.evaluate(x_test,test_y)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C05-fs6Ue3-X",
        "outputId": "75c050eb-eec7-4e82-ade1-5e9807d27686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 15, 15, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 6, 6, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2, 2, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 175,242\n",
            "Trainable params: 174,858\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n",
            "X train shape =  (18456, 32, 32, 1)\n",
            "y train shape =  (18456, 9728)\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4a2e4c671c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y train shape = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#cnn_model = keras.models.load_model(save_path+\"/melspectrogram_model_.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9728) and (None, 10) are incompatible\n"
          ]
        }
      ]
    }
  ]
}